<!DOCTYPE html>
<html lang='en'>
  <head>
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-172959135-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-172959135-1');
</script>
    
    <meta name="google-site-verification" content="gLhqpbQijxKMKurx90GylIsfVCXTRqhPTc7gIHsDD4s" />
    <meta charset='UTF-8'/>
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Projects</title>
    <link rel='stylesheet' href='/css/style.css'/>
    <!--<script src="/js/libraries/prefixfree.min.js"></script>-->
    <link href="https://fonts.googleapis.com/css?family=Merriweather+Sans" rel="stylesheet">
  </head>

  <body>
      <nav>
        <div class="info">
          <div class="name"><a href="/">Jesse Murray</a></div>
          <aside></aside>
        </div>
        <div class="menu">
          <ul>


                <li>

                  <a href="/">Projects</a>

                </li>

                <li>

                  <a href="/skills/">Skills</a>

                </li>


                <li>

                  <a href="/about/">About</a>

                </li>
            


                <li>

                  <a href="/CV/">CV</a>

                </li>


                <li>

                  <a href="/music/">Music</a>

                </li>



                 <li>

                  <a href="/contact/">Contact</a>

                </li>


          </ul>
        </div>
        <div class="social">
            <ul>
            <li><a href=mailto:jessebmurray1@gmail.com><img alt="Email" width="20" height="20" src="/icons/mail.svg"></a></li>
            <li><a href="https://github.com/jessebmurray" target="_blank"><img alt="Github" width="20" height="20" src="/icons/github.svg"></a></li>
            </ul>
        </div>
      </nav>

      <article>
  <header>
    <h2><a href="/">Projects</a></h2>
    <aside>
      
The projects are largely in order of most to least impactful. The titles link to a description and the dates indicate when I was most productive. 

    </aside>
  </header>

  <div class="content">
    <ul class="post-list">


      

     
<li>
          <h2><a class="post-link" href="project_files/JM_NASA_Poster.pdf" target="_blank">
    Algorithmic detection of elemental biosignatures
            </a></h2> <aside class="post-meta"> · Jul 2020</aside>
          <div class="third">
            <div>

              <img src="/images/poter_pca_1_2_3.png">

            </div>
            <div>
            <span class="blurb">
              
In this research, I build machine learning models that classify samples as indicative or non-indicative of life from chemical data. Such models can <a href="https://www.liebertpub.com/doi/full/10.1089/ast.2017.1773" target="_blank">support future life-detection missions</a> by suggesting the distinguishing properties of life and adding redundancy to judgements based on human expertise. I have been working on this research under the mentorship of Diana Gentry for my summer internship at <a href="https://en.wikipedia.org/wiki/Ames_Research_Center" target="_blank">NASA Ames Research Center</a>. This (simplified) poster is for a web presentation I gave to NASA Ames. I will be presenting this research at the <a href="https://agu.confex.com/agu/fm20/prelim.cgi/Paper/710772" target="_blank">2020 American Geophysical Union Fall Meeting</a>.
              
            </span>
            </div>
          </div>
</li>


      
      
      


     
<li>
          <h2><a class="post-link" href="project_files/eyetracking_poster.pdf" target="_blank">Gaze sequences reveal how people gradually arrive at a solution to a word puzzle (anagram)</a></h2> <aside class="post-meta"> · Jul 2019</aside>
          <div class="third">
            <div>

              <img src="/images/img8.png">

            </div>
            <div>
            <span class="blurb">

In this poster, I demonstrate how eye-tracking data on 29 undergraduate subjects solving anagrams 
reveals important pieces of partial solution knowledge. 
This partial solution knowledge is detected early in the problem-solving process, most likely before it is accessible to          <a href="https://www.sciencedirect.com/science/article/abs/pii/S1053810010002667?via%3Dihub" target="_blank">
subjective phenomenal awareness</a>. 
I presented this poster at the Brain and Behavior Conference at the University of Scranton in March 2020. 
I began this research with                                                                                                  <a href="https://www.drew.edu/communications-department/2018/02/13/minjoon-kouh/" target="_blank">
Dr. Minjoon Kouh                                                                                                  </a>  
in May 2019. 
From pilot experiments, we determined that it could be valuable to have the sequence of letters 
people read before reaching a solution. 
However, to accurately collect this data, we had to highly manipulate the anagram stimuli to 
prevent subjects from using their peripheral vision. 
After cleaning and preparing the raw coordinate data with pandas, I produced a                               <a href="https://github.com/jessebmurray/eyetracking/blob/master/seq_data.db" target="_blank">
structured letter sequence dataset                                                                        </a> 
from the experiment. 
I am currently leading a six-member research team to design and implement a new version of our experiment. 
We will be testing additional hypotheses that are based on our latest results. 
You can follow our work on this                                                                        <a href="https://github.com/jessebmurray/eyetracking" target="_blank">
GitHub repository</a>. 
Professor Minjoon Kouh and I intend to publish a paper on our findings.


            </span>
            </div>
          </div>
</li>


      
      

      

      


<li>
          <h2><a class="post-link" href="project_files/polygenic_paper.pdf" target="_blank">A population model of polygenic inheritance</a></h2> <aside class="post-meta"> · Mar 2020</aside>
          <div class="third">
            <div>

              <img alt="" src="/images/individual_offspring_n1000_r50_r_s90_.png">

            </div>
            <div>
            <span class="blurb">
What follows is a non-technical abstract (the technical abstract is in the paper). Are the tallest members of a population mostly the children of tall couples or average/shorter couples? Tall couples are certainly more likely to have tall children, and so you would expect most of the tall children to be from tall couples. On the other hand, there are many more average and shorter height couples than tall couples, thus by their sheer number they might end up producing more tall children overall. So which is it? Does the greater number overcome the lower likelihood, or vice versa? The goal of this project was to derive a compuational model that quantified these effects and answered such questions precisely. What did it find? Well, if 'tall' is to be considered as within the top 10%, then the shorter couples win by far: only 30% of the tall members of a population are from tall parents. This model ended up also having a lot to say about intergenerational mobility and the  parameter values that allow for a stable population over time. The model made verifiable predictions that agreed remarkably well with <a href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/T0HSJ1" target="_blank">Galton’s historic height dataset</a> (R^2 of 0.81) and with <a href="http://www.equality-of-opportunity.org/assets/documents/mobility_geo.pdf" target="_blank">US family income data</a> (R^2 of 0.96). 
              


              
<!-- 

Consider the tallest trees in a forest. Are most of them the offspring of the last generation's 
tallest or shorter/average trees? 
              
Although tall trees have a higher probability of having tall offspring, 
there are many more average/short trees than tall trees. 
              
To answer the question, I created a model of normal population distributions reproducing with regression towards the mean.

The model was based on the                  <a href="https://en.wikipedia.org/wiki/Regression_toward_the_mean#Definition_for_simple_linear_regression_of_data_points" target="_blank">
linear regression</a> equation of           <a href="https://www.nature.com/articles/pr1998502" target="_blank">
polygenic inheritance</a>. 

It assumed small normal distributions about the 
expected-offspring-value from each parent member in the previous 
generation that sum to form the current generation distribution.

A simulation of the model found that past the 72nd percentile, the tallest trees are 
mostly the offspring of shorter/average parents. 

The model was also applied to intergenerational movement between quintiles and obtained
an r<sup>^2</sup> of 0.92 and 0.93 (p < .01) with  Brookings Institution measures of                  <a href="https://www.brookings.edu/blog/social-mobility-memos/2014/10/27/the-inheritance-of-education/" target="_blank">
intergenerational education and income mobility</a>, respectively. 

The high correlations may have resulted from parent values in those distributions producing sub-offspring 
distributions that regress towards the mean. 
-->

            </span>
            </div>
          </div>
</li>

      

            
      


      
     
<li>
          <h2><a class="post-link" href="https://github.com/jessebmurray/COVID-19/blob/master/README.md" target="_blank">
         Using machine learning to predict COVID cases within each US county from the 2018 US Census Estimates data, and visualizations of the evolving relationship between the prevalence of COVID and population density
           </a></h2> <aside class="post-meta"> · May 2020</aside>
          <div class="third">
            <div>

              <img src="/images/xgb_performance.png">

            </div>
            <div>
            <span class="blurb">

In this project, I applied gradient boosted decision trees to 2018 US Census Estimates data to predict the number of confirmed COVID-19 cases per 100,000 within each US county. 
I then identified the counties with the biggest negative residuals, in other words, the counties for which the model most over-predicted the prevalence of COVID-19. 
These counties can be considered the 'luckiest' counties, as they have fared much better than was predicted from their US census data. 
Or perhaps, testing may need to be expanded in these counties, as they may have far more cases than presently reported.

I also explore how the population density of a US county can be used to predict its prevalence of COVID-19, and how this relationship changes as the virus continues its march across urban, suburban, and rural counties alike. 
Lastly, I explore the relative changes in people's interests during the pandemic lockdown by looking at the changes in various google searches at the (previous) US epicenter of the crisis: NYC.
The case data in this project is from May 16, 2020. 

              
            </span>
            </div>
          </div>
</li>


      
      
      

      
      
      
      
      
      
      
      
      
      
      
        <li>
          <h2><a class="post-link" href="https://github.com/jessebmurray/tuning/blob/master/tuning.ipynb" target="_blank">Explorations of a proposed tuning system with comparisons to Pythagorean and twelve-tone equal temperament tuning</a></h2> <aside class="post-meta"> · Feb 2020</aside>
          <div class="third">
            <div>

              <img src="/images/img7.png">

            </div>
            <div>
            <span class="blurb">

I demonstrate a tuning system I thought of, which is compared with the well known pythagorean tuning method. 
These two methods are shown to be derived with a few algebraic rules. 
The two algorithms are compared in terms of their simplicity, correspondance to the consonance of intervals, and errors with the well-established twelve tone equal temperament tuning method (how out of tune they sound). 
The proposed inverse fraction rule is found to have a surprisingly low error rate with the twelve tone inverse.
Here's the proposed tuning algorithm: Begin with the fraction 2/1. Multiply the inverse of the fraction by 2 to get the inverse of the interval. 
Add 1 to the top and bottom of the fraction to get the next interval. Etc. 
The proposed tuning system has some interesting properties. 
For example, the order of intervals in the algorithm corresponds to the <a href="http://www.stat.yale.edu/~zf59/MathematicsOfMusic.pdf" target="_blank">consonance</a> of the intervals. 
On the other hand, the tuning system does not include the tritone and has a larger average absolute error with twelve-tone equal temperament than Pythagorean tuning has (1.91% versus 0.258%). 
Probably the most important discovery is the inverse fraction rule, which locates a close approximation of the twelve-tone inverse from any interval fraction. 
I'm currently working on exploring the intriguing features of the errors for this rule.

            </span>
            </div>
          </div>
        </li>

      
        <li>
          <h2><a class="post-link" href="https://github.com/jessebmurray/landfills/blob/master/landfills_explainer.ipynb" target="_blank">Simulating the amount of non-decomposed municipal solid waste material in US landfills into the future</a></h2> <aside class="post-meta"> · Nov 2019</aside>
          <div class="third">
            <div>

              <img src="/images/img.png">

            </div>
            <div>
            <span class="blurb">

                I simulate the growth in the amount of non-decomposed material in US landfills. I use an exponential decay model of decomposition and literature-provided parameter values for decomposition times, MSW material densities, MSW material historical and projected annual landfill additions, and US landfill depths. 
              Main results: By the year 2100, plastic is the largest contributor to total US landfill size in terms of mass and the majority contributor in terms of volume and land area. However, thousands of years into the future, glass becomes the majority contributor due to its 1,000,000-year decomposition time. The amount of non-decomposed material is projected to take up about 400 sq km of US land area by 2100, and about 33,000 sq km (roughly the size of Massachusetts) at equilibrium (when rate of decomposition equals rate of addition). If the US stops landfilling glass in the year 2200, the equilibrium land area is shown to be reduced to about half the size of Rhode Island.

            </span>
            </div>
          </div>
        </li>


     
        <li>
          <h2><a class="post-link" href="project_files/leveraged_index.pdf" target="_blank">An analysis of the returns from simulated leveraged index funds since 1985</a></h2> <aside class="post-meta"> · Aug 2017</aside>
          <div class="third">
            <div>

              <img src="/images/img3.png">

            </div>
            <div>
            <span class="blurb">

                I simulate index funds with annual rebalancing of leveraging rates from 0% to 100% across 1,144 historical 10-year periods each spaced one week apart. The index funds used are: The NASDAQ Composite, the S&P 500, and the Dow Jones Industrial Average. Main results: All indices had higher median returns with increased leverage, but there were diminishing and even decreasing median returns as leverage increased past 50%. For example: at 50% leverage, the S&P 500 had a median 10-year compound interest rate of 12% as compared to 8.3% for unleveraged. Even in the worst 20-year period (out of 624), moderate amounts of leverage (up to 40%) had higher compound interest rates for all three indices.  

            </span>
            </div>
          </div>
        </li>


        <li>
          <h2><a class="post-link" href="https://github.com/jessebmurray/child_mortality_fertility_rates/blob/master/child_mortality_fertility_rates_explainer.ipynb" target="_blank">The probabilistic implications of the high pre-1800 global child mortality and fertility rates</a></h2> <aside class="post-meta"> · June 2019</aside>
          <div class="third">
            <div>

              <img src="/images/prob_rep_success.png">

            </div>
            <div>
            <span class="blurb">

I lend support to the <a href="https://www.ncbi.nlm.nih.gov/books/NBK233807/" target="_blank">theory</a> that the very high pre-1800 global fertility rate was a response to the very high global child mortality rate. I use probabilities from a binomial distribution to show how the desire for parents to have at least two of their children survive into adulthood could have led to a strategy of having many children, among other factors. Main results: Having 3 children instead of 2 doubled the probability that at least 2 survive past five years old (from 32% to 60%). When having 6 children (the pre-1800 average), parents obtained a 94% chance of reproductive success, i.e., that at least 2 survive past childhood. It is postulated that around this number of children, the reproductive benefits of having an additional (seventh) child would be outweighed by the costs. 


            </span>
            </div>
          </div>
        </li>


        <li>
          <h2><a class="post-link" href="project_files/college_majors.pdf" target="_blank">The relative competitiveness and economic rewards of college majors</a></h2> <aside class="post-meta"> · Mar 2019</aside>
          <div class="third">
            <div>

              <img src="/images/img4.png">

            </div>
            <div>
            <span class="blurb">
I compare the relative competitiveness and economic rewards (income) of different college majors using SAT score and income data. Main results: The English, Language, and Philosophy/religious majors, i.e., humanities majors, are both very competitive as well as very economically unrewarding. On the other hand, the Physical science and Biology majors are highly competitive and relatively economically unrewarding, that is, until a graduate degree is obtained. Then, those majors become very economically rewarding. For overall score - in terms of getting the most economic reward for the least competitiveness - the 'best' undergraduate degrees are Engineering and Computer Science.
              
<!-- 
I compare the relative competitiveness and economic rewards of different college majors both for bachelor's degree only as well as graduate degree holders using SAT score and income data. Main results: The English, Language, and Philosophy/religious are both highly competitive and highly economically unrewarding. Physical science and Biology majors are highly competitive and relatively economically unrewarding, until a graduate degree is obtained. Then those majors become highly economically rewarding. For overall score - in terms of maximizing the economic rewards as well as the ratio of the rewards to the competitiveness - if one only obtains a bachelor's degree the 'best' majors are Engineering and Computer Science. 
-->
            </span>
            </div>
          </div>
        </li>



        <li>
          <h2><a class="post-link" href="https://docs.google.com/spreadsheets/d/1ay8tjj6jVbaNAdIJvGYLraRV3cE13I63lFXYeF3J29g/edit?usp=sharing" target="_blank">Time travel with special relativity (general hopefully coming soon)</a></h2> <aside class="post-meta"> · Jul 2019</aside>
          <div class="third">
            <div>
                  <img src="/images/img2.png">
            </div>
            <div>
            <span class="blurb">
              
Is time travel technically possible? Well, yes! Although, you can only travel forward in time, and the energy requirements are rather ridiculous. How do you do it? You go fast, very fast. In doing so, you take advantage of the remarkable fact that light moves away from all observers at the same speed. That is, if someone drives past you on a motorcycle going 90% the speed of light and turns on a flashlight, the light from the flashlight will go away from you <i> and him </i> at the same speed. This seemingly impossible fact leads mathematically to all sorts of wondrous effects: from the Earth shrinking to the width of a pancake, to seeing radio waves. (Actually there is one other way to time travel, which is to get next to something heavy, but I haven't covered that yet.) In this project, I thought it would be cool to create a virtual time machine. Simply enter the date in the future you'd like to go to and how fast you'd like to travel, then see all the amazing things that will happen during your journey, like how much fuel you'll need for your spaceship (probably a lot). I made this when I was the TA for a special relativity class at the <a href="http://www.drew.edu/governors-school/" target="_blank">New Jersey Governor’s School in the Sciences</a>. I hoped to show how the significant energy requirements of time travel make it practically out of reach for the foreseeable future. I hope to come back to this project eventually and make a fun web application.
            </span>
            </div>
          </div>
        </li>




      

        <li>
          <h2><a class="post-link" href="project_files/nutrition.pdf" target="_blank">Comparing foods with calculations on nutrition facts data</a></h2> <aside class="post-meta"> · Aug 2018</aside>
          <div class="third">
            <div>

              <img src="/images/img6.png">

            </div>
            <div>
            <span class="blurb">

                I compare foods in terms of overall healthiness score, protein content, energy density, cost, and others. I standardize comparisons across diverse food types by using energy measurements, i.e., the contents of a day's worth (~2000 calories). The data I use are price, mass, energy, total fat, saturated fat, polyunsaturated fat, monounsaturated fat, trans fat, carbohydrates, fiber, protein, and glycemic index.

            </span>
            </div>
          </div>
        </li>



        <li>
          <h2><a class="post-link" href="project_files/climate_change.pdf" target="_blank">Climate change and the science behind emissions</a></h2> <aside class="post-meta"> · Feb 2020</aside>
          <div class="third">
            <div>

              <img src="/images/world.png">

            </div>
            <div>
            <span class="blurb">

Understanding and reading deeply about global warming has long been a hobby of mine, in fact, I am a contributor to the <a href="https://en.wikipedia.org/wiki/Global_warming" target="_blank">global warming Wikipedia page</a>. To me, global warming presents a fascinating multi-disciplinary scientific and engineering problem that requires a good understanding of physics and chemistry. To avoid exceeding 1.5ºC warming, the world needs to get emissions to <a href="https://www.ipcc.ch/sr15/chapter/spm/spm-c/spm3a/" target="_blank">zero by 2050</a>. This daunting challenge seems at first to merely be about <a href="https://kleinmanenergy.upenn.edu/sites/default/files/Getting_to_Zero.pdf" target="_blank">energy sourcing and storage</a>. However, one eventually discovers a dramatic problem in that we must eliminate many greenhouse gas producing chemical reactions that are currently deeply fundamental to industrialized life (steel, concrete, fertilizer, etc.). These are the slides of a 30-minute talk I gave for a student club, in which I discussed the many diverse sources of anthropogenic carbon emissions in great detail. I also discussed the problem as it relates to public policy and included some innovative ideas that are gaining attention. The talk came from my passion for multi-disciplinary science, and it was created entirely in my free time, purely out of my deep interest in the topic. 
            </span>
            </div>
          </div>
        </li>

      


    </ul>
  </div>

  <footer>
    <aside>
        

   
 
I have some project-ideas still on my might-do/unexplored list, they are on topics including: 

<p> 

    <li> A cost-benefit model of speeding in relation to the ticket price and the probability of getting pulled over. </li>

  <li>
    Training a model to recognize the features of better vs. worse melodies, checking the model against the characteristics of good 
  melody as proposed by <a href="https://www.juilliard.edu/music/faculty/laitz-steven" target="_blank"><u>Steven Laitz</u></a>.
  </li>
  
    <li> A geographic visualization of weather data through the feels-like scale, the seasonal chance of pretty/ugly weather events such as snow 
  and rainfall, and the proportion of time spent below freezing point. 
  </li>

<li>
    The fastest walking path through the Manhattan grid based on start and end locations, taking into account waiting times at crosswalks; i.e., it is not sides a and b of a right triangle.
</li>

<!--
<li>
    Listing the non-proper-noun words of the most common words in English and grouping together those that are synonyms 
  of one another to obtain the number of unique semantic representations as compared to the number of unique words. Playing around with 
  the resulting data on words per unique semantic representation.
</li>
-->


<li>
    Using data on people's music listening habits to better understand the pleasantness of a song as a function of the number 
  of listens. I believe meaningful results could be obtained with even a relatively small sample size of ~50. 
</li>
  
</p> 

I usually narrow down the most promising idea to work on, which is why not all of these will become completed projects. 

<!-- 
<br>
<br>

The CSS for this website was drawn from the website of someone whose work I greatly admire: <a href="https://aatishb.com/" target="_blank"><u>Aatish Bhatia</u></a>. 
-->
      
    </aside>
  </footer>
</article>



  <script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script></body>

</html>
