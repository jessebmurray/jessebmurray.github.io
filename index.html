<!DOCTYPE html>
<html lang='en'>
  <head>
    <meta name="google-site-verification" content="gLhqpbQijxKMKurx90GylIsfVCXTRqhPTc7gIHsDD4s" />
    <meta charset='UTF-8'/>
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Projects</title>
    <link rel='stylesheet' href='/css/style.css'/>
    <!--<script src="/js/libraries/prefixfree.min.js"></script>-->
    <link href="https://fonts.googleapis.com/css?family=Merriweather+Sans" rel="stylesheet">
  </head>

  <body>
      <nav>
        <div class="info">
          <div class="name"><a href="/">Jesse Murray</a></div>
          <aside></aside>
        </div>
        <div class="menu">
          <ul>


                <li>

                  <a href="/">Projects</a>

                </li>

                <li>

                  <a href="/skills/">Skills</a>

                </li>


                <li>

                  <a href="/about/">About</a>

                </li>
            


                <li>

                  <a href="/CV/">CV</a>

                </li>


                <li>

                  <a href="/music/">Music</a>

                </li>



                 <li>

                  <a href="/contact/">Contact</a>

                </li>


          </ul>
        </div>
        <div class="social">
            <ul>
            <li><a href=mailto:jmurray@drew.edu><img alt="Email" width="20" height="20" src="/icons/mail.svg"></a></li>
            <li><a href="https://github.com/jessebmurray" target="_blank"><img alt="Github" width="20" height="20" src="/icons/github.svg"></a></li>
            </ul>
        </div>
      </nav>

      <article>
  <header>
    <h2><a href="/">Projects</a></h2>
    <aside>
      
The projects are in order of most to least impactful. The dates show when I was most productively working on the project. 
Pressing on a title will open an explanatory paper, research poster or jupyter notebook in a new tab.

    
    
    
    </aside>
  </header>

  <div class="content">
    <ul class="post-list">


      
      
      
      


  <li>
          <h2><a class="post-link" href="project_files/polygenic_paper.pdf" target="_blank">A population model of polygenic inheritance</a></h2> <aside class="post-meta"> · Mar 2020</aside>
          <div class="third">
            <div>

              <img alt="" src="/images/trimmed_parameters_side_n600_z6_.png">

            </div>
            <div>
            <span class="blurb">
A population model of polygenic inheritance is derived from the linear regression and normality of polygenic traits as first discovered by Francis Galton in the late 19th century. A simulation of the model is run with the measured parameter values r and r_s in the data from Galton’s famous study on the heights of adult children and their parents. The simulation is shown to successfully construct an offspring generation that highly replicates the parent generation - indicating a stable population distribution between generations. A quintile transition matrix of intergenerational mobility is created, obtaining an R^2 of 0.81 (p < 0.001) with Galton’s data and an R^2 of 0.96 (p < 0.001) with US family income data. Calculations of intergenerational upward persistence are made, which highly correspond to measurements in Galton’s data. An equilibrium point is obtained at the percentile score of 71.7%, which compares well with the measured equilibrium percentile score of 72.2% in Galton’s data. (The equilibrium indicates that those above the 72nd percentile are equally likely to be the children of parents above the 72nd percentile and of parents below the 72nd percentile.) Furthermore, the paper demonstrates the roles r and r_s have in determining population variance stability between generations.
I am in the process of writing a paper to be submitted to a journal. You can also check out my <a href="https://github.com/jessebmurray/polygenic" target="_blank">GitHub repository</a> for the project, where all my work is. 

              
              

              
              
              
<!-- 

Consider the tallest trees in a forest. Are most of them the offspring of the last generation's 
tallest or shorter/average trees? 
              
Although tall trees have a higher probability of having tall offspring, 
there are many more average/short trees than tall trees. 
              
To answer the question, I created a model of normal population distributions reproducing with regression towards the mean.

The model was based on the                  <a href="https://en.wikipedia.org/wiki/Regression_toward_the_mean#Definition_for_simple_linear_regression_of_data_points" target="_blank">
linear regression</a> equation of           <a href="https://www.nature.com/articles/pr1998502" target="_blank">
polygenic inheritance</a>. 

It assumed small normal distributions about the 
expected-offspring-value from each parent member in the previous 
generation that sum to form the current generation distribution.

A simulation of the model found that past the 72nd percentile, the tallest trees are 
mostly the offspring of shorter/average parents. 

The model was also applied to intergenerational movement between quintiles and obtained
an r<sup>^2</sup> of 0.92 and 0.93 (p < .01) with  Brookings Institution measures of                  <a href="https://www.brookings.edu/blog/social-mobility-memos/2014/10/27/the-inheritance-of-education/" target="_blank">
intergenerational education and income mobility</a>, respectively. 

The high correlations may have resulted from parent values in those distributions producing sub-offspring 
distributions that regress towards the mean. 

After March 7, I will be working with Professor Minjoon Kouh on preparing this paper for journal submission.



-->

            </span>
            </div>
          </div>

</li>

      

     
        <li>
          <h2><a class="post-link" href="project_files/eyetracking_poster.pdf" target="_blank">Gaze sequences reveal how people gradually arrive at a solution to a word puzzle (anagram)</a></h2> <aside class="post-meta"> · Jul 2019</aside>
          <div class="third">
            <div>

              <img src="/images/img8.png">

            </div>
            <div>
            <span class="blurb">

In this poster, I demonstrate how eye-tracking data on 29 undergraduate subjects solving anagrams 
reveals important pieces of partial solution knowledge. 
This partial solution knowledge is detected early in the problem-solving process, most likely before it is accessible to          <a href="https://www.sciencedirect.com/science/article/abs/pii/S1053810010002667?via%3Dihub" target="_blank">
subjective phenomenal awareness</a>. 
I am presenting this poster at the University of Scranton Brain and Behavior Conference on March 7th. 
I began this research with                                                                                                  <a href="https://www.drew.edu/communications-department/2018/02/13/minjoon-kouh/" target="_blank">
Dr. Minjoon Kouh                                                                                                  </a>  
in May 2019. 
From pilot experiments, we determined that it could be valuable to have the sequence of letters 
people read before reaching a solution. 
However, to accurately collect this data, we had to highly manipulate the anagram stimuli to 
prevent subjects from using their peripheral vision. 
After cleaning and preparing the raw coordinate data with pandas, I produced a                               <a href="https://github.com/jessebmurray/eyetracking/blob/master/seq_data.db" target="_blank">
structured letter sequence dataset                                                                        </a> 
from the experiment. 
I am currently leading a six-member research team to design and implement a new version of our experiment. 
We will be testing additional hypotheses that are based on our latest results. 
You can follow our work on this                                                                        <a href="https://github.com/jessebmurray/eyetracking" target="_blank">
GitHub repository</a>. 
By the end of this semester, Professor Minjoon Kouh and I intend to publish a paper on our findings.


            </span>
            </div>
          </div>
        </li>


      
      
      

      
      
      
      
      
      
      
        <li>
          <h2><a class="post-link" href="https://github.com/jessebmurray/tuning/blob/master/tuning.ipynb" target="_blank">Explorations of a proposed tuning system with comparisons to Pythagorean and twelve-tone equal temperament tuning</a></h2> <aside class="post-meta"> · Feb 2020</aside>
          <div class="third">
            <div>

              <img src="/images/img7.png">

            </div>
            <div>
            <span class="blurb">

I demonstrate a tuning system I thought of, which is compared with the well known pythagorean tuning method. 
These two methods are shown to be derived with a few algebraic rules. 
The two algorithms are compared in terms of their simplicity, correspondance to the consonance of intervals, and errors with the well-established twelve tone equal temperament tuning method (how out of tune they sound). 
The proposed inverse fraction rule is found to have a surprisingly low error rate with the twelve tone inverse.
Here's the proposed tuning algorithm: Begin with the fraction 2/1. Multiply the inverse of the fraction by 2 to get the inverse of the interval. 
Add 1 to the top and bottom of the fraction to get the next interval. Etc. 
The proposed tuning system has some interesting properties. 
For example, the order of intervals in the algorithm corresponds to the <a href="http://www.stat.yale.edu/~zf59/MathematicsOfMusic.pdf" target="_blank">consonance</a> of the intervals. 
On the other hand, the tuning system does not include the tritone and has a larger average absolute error with twelve-tone equal temperament than Pythagorean tuning has (1.91% versus 0.258%). 
Probably the most important discovery is the inverse fraction rule, which locates a close approximation of the twelve-tone inverse from any interval fraction. 
I'm currently working on exploring the intriguing features of the errors for this rule.

            </span>
            </div>
          </div>
        </li>

      
        <li>
          <h2><a class="post-link" href="https://github.com/jessebmurray/landfills/blob/master/landfills_explainer.ipynb" target="_blank">Simulating the amount of non-decomposed municipal solid waste material in US landfills into the future</a></h2> <aside class="post-meta"> · Nov 2019</aside>
          <div class="third">
            <div>

              <img src="/images/img.png">

            </div>
            <div>
            <span class="blurb">

                I simulate the growth in the amount of non-decomposed material in US landfills. I use an exponential decay model of decomposition and literature-provided parameter values for decomposition times, MSW material densities, MSW material historical and projected annual landfill additions, and US landfill depths. 
              Main results: By the year 2100, plastic is the largest contributor to total US landfill size in terms of mass and the majority contributor in terms of volume and land area. However, thousands of years into the future, glass becomes the majority contributor due to its 1,000,000-year decomposition time. The amount of non-decomposed material is projected to take up about 400 sq km of US land area by 2100, and about 33,000 sq km (roughly the size of Massachusetts) at equilibrium (when rate of decomposition equals rate of addition). If the US stops landfilling glass in the year 2200, the equilibrium land area is shown to be reduced to about half the size of Rhode Island.

            </span>
            </div>
          </div>
        </li>


     
        <li>
          <h2><a class="post-link" href="project_files/leveraged_index.pdf" target="_blank">An analysis of the returns from simulated leveraged index funds since 1985</a></h2> <aside class="post-meta"> · Aug 2017</aside>
          <div class="third">
            <div>

              <img src="/images/img3.png">

            </div>
            <div>
            <span class="blurb">

                I simulate index funds with annual rebalancing of leveraging rates from 0% to 100% across 1,144 historical 10-year periods each spaced one week apart. The index funds used are: The NASDAQ Composite, the S&P 500, and the Dow Jones Industrial Average. Main results: All indices had higher median returns with increased leverage, but there were diminishing and even decreasing median returns as leverage increased past 50%. For example: at 50% leverage, the S&P 500 had a median 10-year compound interest rate of 12% as compared to 8.3% for unleveraged. Even in the worst 20-year period (out of 624), moderate amounts of leverage (up to 40%) had higher compound interest rates for all three indices.  

            </span>
            </div>
          </div>
        </li>


        <li>
          <h2><a class="post-link" href="https://github.com/jessebmurray/child_mortality_fertility_rates/blob/master/child_mortality_fertility_rates_explainer.ipynb" target="_blank">The probabilistic implications of the high pre-1800 global child mortality and fertility rates</a></h2> <aside class="post-meta"> · June 2019</aside>
          <div class="third">
            <div>

              <img src="/images/img5.png">

            </div>
            <div>
            <span class="blurb">

                  I lend support to the <a href="https://www.ncbi.nlm.nih.gov/books/NBK233807/" target="_blank">theory</a> that the very high pre-1800 global fertility rate was a response to the very high global child mortality rate. I use probabilities from a binomial distribution to show how the desire for parents to have at least two of their children survive into adulthood could have led to a strategy of having many children, among other factors. Main results: Having 3 children instead of 2 doubled the probability that at least 2 survive past 5 years old (from 32% to 60%). When having 6 children, parents obtained a 94% chance that at least 2 survive past childhood. Having 7 then 8 children marginally increased the probability to 97% then 99%, respectively. 


            </span>
            </div>
          </div>
        </li>


        <li>
          <h2><a class="post-link" href="project_files/college_majors.pdf" target="_blank">The relative competitiveness and economic rewards of college majors</a></h2> <aside class="post-meta"> · Mar 2019</aside>
          <div class="third">
            <div>

              <img src="/images/img4.png">

            </div>
            <div>
            <span class="blurb">

                I compare the relative competitiveness and economic rewards of different college majors both for bachelor's degree only as well as graduate degree holders using SAT score and income data. Main results: The English, Language, and Philosophy/religious are both highly competitive and highly economically unrewarding. Physical science and Biology majors are highly competitive and relatively economically unrewarding, until a graduate degree is obtained. Then those majors become highly economically rewarding. For overall score - in terms of maximizing the economic rewards as well as the ratio of the rewards to the competitiveness - if one only obtains a bachelor's degree the 'best' majors are Engineering and Computer Science. 

            </span>
            </div>
          </div>
        </li>



        <li>
          <h2><a class="post-link" href="https://docs.google.com/spreadsheets/d/1ay8tjj6jVbaNAdIJvGYLraRV3cE13I63lFXYeF3J29g/edit?usp=sharing" target="_blank">Time travel with special relativity (general hopefully coming soon)</a></h2> <aside class="post-meta"> · Jul 2019</aside>
          <div class="third">
            <div>
                  <img src="/images/img2.png">
            </div>
            <div>
            <span class="blurb">
                I demonstrate how one can time travel by moving very fast and show some of the incredible effects that occur. (There is one other way to time travel: get next to something very heavy.)
              The effects - from watching the earth shrink to the width of a pancake to being able to see radio waves - are exactly calculated when you decide your date of departure, date of arrival (in the future), and how far into the future you want to go for every one hour of time travel (a day, a year, a millennium, etc.).
              But beware, once you travel to the future, you can never come back!
              I made this when I was the TA for a special relativity class at the <a href="http://www.drew.edu/governors-school/" target="_blank">New Jersey Governor’s School in the Sciences</a>, a science program for talented New Jersey high school students. 
              I hoped to provide a fun explanation of the effects of moving at high speeds and the significant energy requirements that make time travel technically possible but practically out of reach.
              I hope to come back to this project when I have some free time and make a javascript application.
            </span>
            </div>
          </div>
        </li>




      

        <li>
          <h2><a class="post-link" href="project_files/nutrition.pdf" target="_blank">Comparing foods with calculations on nutrition facts data</a></h2> <aside class="post-meta"> · Aug 2018</aside>
          <div class="third">
            <div>

              <img src="/images/img6.png">

            </div>
            <div>
            <span class="blurb">

                I compare foods in terms of overall healthiness score, protein content, energy density, cost, and others. I standardize comparisons across diverse food types by using energy measurements, i.e., the contents of a day's worth (~2000 calories). The data I use are price, mass, energy, total fat, saturated fat, polyunsaturated fat, monounsaturated fat, trans fat, carbohydrates, fiber, protein, and glycemic index.

            </span>
            </div>
          </div>
        </li>



        <li>
          <h2><a class="post-link" href="project_files/climate_change.pdf" target="_blank">Slides from a talk on climate change and the science behind emissions</a></h2> <aside class="post-meta"> · Feb 2020</aside>
          <div class="third">
            <div>

              <img src="/images/world.png">

            </div>
            <div>
            <span class="blurb">

                Understanding and reading deeply about climate change has long been a hobby of mine, probably because it presents a multi-disciplinary scientific and engineering problem that heavily relies on understanding physics and chemistry.
                Specifically, the problem we are faced with is how to get emissions to <a href="https://www.ipcc.ch/sr15/chapter/spm/spm-c/spm3a/" target="_blank">zero by 2050</a>.
                At first, the problem seems to be about <a href="https://en.wikipedia.org/wiki/Energy" target="_blank">energy</a> sourcing and storage. However, one quickly discovers that the world needs to solve a wide array of seemingly vital chemical reactions.
                These are the slides of a 30-minute talk I gave for a student club, in which I discussed the science in great detail and crystallized my knowledge on this important issue.
                I also discussed the problem as it relates to public policy and included some innovative solutions that are gaining attention.
                The talk came from my passion for physics and multi-disciplinary science, and it was created entirely in my free time, purely out of my deep interest in the topic. 

            </span>
            </div>
          </div>
        </li>

      


    </ul>
  </div>

  <footer>
    <aside>
        

   
 
I have some project-ideas still on my might-do/unexplored list, they are on topics including: 

<p> 

    <li> A cost-benefit model of speeding in relation to the ticket price and the probability of getting pulled over. </li>

  <li>
    Training a model to recognize the features of better vs. worse melodies, checking the model against the characteristics of good 
  melody as proposed by <a href="https://www.juilliard.edu/music/faculty/laitz-steven" target="_blank"><u>Steven Laitz</u></a>.
  </li>
  
    <li> A visualization of weather data through the feels-like scale, the seasonal chance of pretty/ugly weather events such as snow 
  and rainfall, and the proportion of time spent below freezing point. 
  </li>

<li>
    The fastest walking path through the Manhattan grid based on start and end locations, taking into account waiting times at crosswalks; i.e., it is not sides a and b of a right triangle.
</li>

<li>
    Listing the non-proper-noun words of the most common words in English and grouping together those that are synonyms 
  of one another to obtain the number of unique semantic representations as compared to the number of unique words. Playing around with 
  the resulting data on words per unique semantic representation.
</li>



<li>
    Using data on people's music listening habits to better understand the pleasantness of a song as a function of the number 
  of listens. I believe meaningful results could be obtained with even a relatively small sample size of ~50.
</li>
  
</p> 


I usually narrow down the most promising idea to work on, which is why not all of these will become completed projects. 
      
<br>
<br>


The CSS for this website was drawn from the website of someone whose work I greatly admire: <a href="https://aatishb.com/" target="_blank"><u>Aatish Bhatia</u></a>. 
      
    </aside>
  </footer>
</article>



  <script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script></body>

</html>
